# AI-and-Cybersecurity-Project
Reproducing results of paper: Demontis, Ambra, et al. "Why do adversarial attacks transfer? Explaining transferability of evasion and poisoning attacks." 28th USENIX security symposium (USENIX security 19). 2019.

Attacks implemented for MNIST dataset on digits 5 and 9 for both Evasion and Poisoning atack.

We added code in 06_MNIST_dataset.ipynb for Running Attack for each Classifier (multiple surrogate model at once) where default code supported only 1 surrogate model at a time. We did it against increasing maximum perturbation Îµ for  Evasion attack and increasing Fraction of Poisoning Points for Poisioning attack.

Run the cells in Colab.

Paper :https://www.usenix.org/system/files/sec19-demontis.pdf
